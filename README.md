# 🤖 AI-Generated Code Reference

> **Code Generated by:** **Claude Sonnet 4**, **Claude Sonnet 4.5**, and **Claude Sonnet 4.5 Thinking** (Anthropic's advanced AI assistants)

## 📚 References

This project builds upon the following research papers on exoplanet detection using machine learning:

1. **Exoplanet detection using machine learning**
   - DOI: https://doi.org/10.1093/mnras/stab3692
   - *Monthly Notices of the Royal Astronomical Society*

2. **Assessment of Ensemble-Based Machine Learning Algorithms for Exoplanet Identification**
   - DOI: https://doi.org/10.3390/electronics13193950
   - *Electronics Journal*

These papers provide detailed studies on machine learning techniques applied to light curve datasets from Kepler, K2, and TESS missions for detecting exoplanets, which directly informed the development of this pipeline.

---

# Wednesday Wings - Space Apps Hackathon

Exoplanet Detection and Analysis Pipeline for NASA Space Apps Challenge 2025

> **AI Assistants:** Claude Sonnet 4, Claude Sonnet 4.5, Claude Sonnet 4.5 Thinking | **Generation Date:** January 2025

## 🚀 Quick Start

### Complete Data Pipeline
Run the full data processing pipeline (sanitization + normalization):

```bash
cd Backend/sanitization
python run_all_sanitizers.py
```

This will automatically:
1. **Sanitize** raw exoplanet data (K2, KOI, TOI datasets)
2. **Normalize** cleaned data to [0, 1] range for ML training
3. Generate quality reports and visualizations

### Manual Steps (if needed)

**Sanitization only:**
```bash
cd Backend/sanitization
python run_all_sanitizers.py
```

**Normalization only:**
```bash
cd Backend/normalisation
python improved_normalizer.py
```

## 📁 Project Structure

```
Backend/
├── sanitization/          # Data cleaning and validation
├── normalisation/          # ML-ready data normalization  
├── data/
│   ├── raw/               # Original datasets
│   ├── sanitized/         # Cleaned datasets
│   └── normalised/        # ML-ready normalized data
├── cleaned_datasets/      # Final cleaned CSV files
└── plots/                 # Data quality visualizations
```

## 🔄 Data Pipeline

1. **Raw Data** → **Sanitization** → **Cleaned Data** → **Normalization** → **ML-Ready Data**

### Sanitization Process
- Removes invalid/duplicate entries
- Standardizes column formats
- Handles missing values
- Generates quality reports

### Normalization Process  
- Scales all features to [0, 1] range
- Preserves original data relationships
- Excludes identifier columns
- Creates ML training files

## 📊 Output Files

After running the pipeline, you'll have:

**Cleaned Data:**
- `Backend/cleaned_datasets/k2_cleaned.csv`
- `Backend/cleaned_datasets/koi_cleaned.csv` 
- `Backend/cleaned_datasets/toi_cleaned.csv`

**Normalized Data (ML-Ready):**
- `Backend/data/normalised/k2_normalised.csv`
- `Backend/data/normalised/koi_normalised.csv`
- `Backend/data/normalised/toi_normalised.csv`

**Supporting Files:**
- Scaling objects (`.joblib`) for inverse transforms
- Feature lists for ML pipelines
- Quality visualization plots

## ✅ Data Quality

All normalized data is guaranteed to:
- Have values in exact [0, 1] range
- Preserve original data relationships and ratios
- Be ready for immediate ML training
- Include comprehensive quality validation

---

*NASA Space Apps Challenge 2025 - Wednesday Wings Team*
